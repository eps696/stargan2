{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "StarGAN2_colab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzA1-mt88AO_"
      },
      "source": [
        "# StarGAN2 operations\n",
        "\n",
        "This Colab is from repository https://github.com/eps696/stargan2.  \n",
        "Please read instructions and hints there, regarding data preparation and training process.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7IFfx8GQIAQm"
      },
      "source": [
        "\n",
        "**Run this cell after each session restart**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkbcraCUaPEy"
      },
      "source": [
        "#@title General setup { display-mode: \"form\", run: \"auto\" }\n",
        "\n",
        "!pip install gputil ffpb\n",
        "\n",
        "import os\n",
        "from base64 import b64encode\n",
        "\n",
        "import ipywidgets as ipy\n",
        "from IPython.display import HTML, Image, display, clear_output\n",
        "# from IPython.core.interactiveshell import InteractiveShell\n",
        "# InteractiveShell.ast_node_interactivity = \"all\"\n",
        "# from google.colab import output, files\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "!apt-get -qq install ffmpeg\n",
        "from google.colab import drive\n",
        "drive.mount('/G', force_remount=True)\n",
        "# gdir = !ls /G/\n",
        "# gdir = '/G/%s/' % str(gdir[0])\n",
        "gdir = '/G/MyDrive/'\n",
        "%cd $gdir\n",
        "\n",
        "#@markdown Copying StarGAN2 to the directory below on your Google drive (creating it, if it doesn't exist):\n",
        "work_dir = 'stargan2' #@param {type:\"string\"}\n",
        "#@markdown NB: All paths below are relative to this directory (except the archive with source images on the next step). \n",
        "\n",
        "#@markdown NB: Avoid connecting Google drive manually via the icon in Files section on the left. Doing so may break further operations.\n",
        "\n",
        "work_dir = os.path.join(gdir, work_dir)\n",
        "if not os.path.isdir(work_dir):\n",
        "  !git clone git://github.com/eps696/stargan2 $work_dir\n",
        "%cd $work_dir\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "clear_output()\n",
        "\n",
        "from src.utilgan import file_list, img_list, basename\n",
        "model = ''\n",
        "def model_select(work_dir):\n",
        "  models = file_list(work_dir, 'ckpt', subdir=True)\n",
        "  models = [m.replace(work_dir, '') for m in models if not 'optims' in basename(m)]\n",
        "  global model\n",
        "  model = models[0]\n",
        "  def on_change(change):\n",
        "    global model\n",
        "    if change['type'] == 'change' and change['name'] == 'value':\n",
        "      model = change['new']\n",
        "      if model[0]=='/': model = model[1:]\n",
        "      model = os.path.join(work_dir, model)\n",
        "      print('.. selected model', model)\n",
        "  model_select = ipy.Dropdown(options=models, description='Found models:', style={'description_width': 'initial'}, layout={'width': 'max-content'})\n",
        "  display(model_select)\n",
        "  model_select.observe(on_change)\n",
        "# model_select(work_dir)\n",
        "\n",
        "def makevid(seq_dir, size=None):\n",
        "  char_len = len(basename(img_list(seq_dir)[0]))\n",
        "  out_sequence = seq_dir + '/%0{}d.jpg'.format(char_len)\n",
        "  out_video = seq_dir + '.mp4'\n",
        "  !ffpb -y -i $out_sequence -crf 18 $out_video\n",
        "  data_url = \"data:video/mp4;base64,\" + b64encode(open(out_video,'rb').read()).decode()\n",
        "  wh = '' if size is None else 'width=%d height=%d' % (size, size)\n",
        "  return \"\"\"<video %s controls><source src=\"%s\" type=\"video/mp4\"></video>\"\"\" % (wh, data_url)\n",
        "\n",
        "# Hardware check\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "import GPUtil as GPU\n",
        "gpu = GPU.getGPUs()[0]\n",
        "!nvidia-smi -L\n",
        "print(\"GPU RAM {0:.0f}MB | Free {1:.0f}MB)\".format(gpu.memoryTotal, gpu.memoryFree))\n",
        "print('\\nDone!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWpWFeyO8APF"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_LGhTfV8APG"
      },
      "source": [
        "First, let's prepare the multi-domain dataset. Ensure all your images are RGB (3 channels). Ensure the minimum size (by any side) is bigger than model resolution below.\n",
        "Collect your dataset as described [in the repo](https://github.com/eps696/stargan2).\n",
        "\n",
        "Upload zip-archive with images onto Google drive and type its path below (relative to G-drive root). Run cell below every time, once you get new Colab runtime (cause we place the dataset on local disc for maximum speed)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "tEmNzQmm0t_o"
      },
      "source": [
        "#@title Data setup \n",
        "dataset = 'test' #@param {type:\"string\"}\n",
        "source = 'stargan2/data/test.zip' #@param {type:\"string\"}\n",
        "data_dir = os.path.join('/content', dataset)\n",
        "\n",
        "# cleanup previous attempts\n",
        "![ -d \"/content/tmp\" ]; rm -rf /content/tmp \n",
        "![ -d $data_dir ]; rm -rf $data_dir\n",
        "\n",
        "!mkdir /content/tmp\n",
        "%cd /content/tmp\n",
        "fpath = os.path.join(gdir, source)\n",
        "!unzip -o -q $fpath\n",
        "unpack_dir = os.path.join('/content/tmp', basename(source))\n",
        "!mv $unpack_dir $data_dir\n",
        "%cd $work_dir\n",
        "!ls $data_dir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfczVF0W8APH"
      },
      "source": [
        "Now, we can train StarGAN2 on the prepared dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKmktOPb8APH",
        "cellView": "form"
      },
      "source": [
        "#@title Train\n",
        "%cd $work_dir\n",
        "dataset = 'test' #@param {type:\"string\"}\n",
        "size = 256 #@param [256,512]\n",
        "batch =  6#@param {type:\"integer\"}\n",
        "lambda_ds = 2. #@param {type:\"number\"}\n",
        "lambda_cyc = 1. #@param {type:\"number\"}\n",
        "lambda_sty = 1. #@param {type:\"number\"}\n",
        "steps_k = 100 #@param {type:\"integer\"}\n",
        "sample_every_k =  0.01#@param {type:\"number\"}\n",
        "save_every_k = 0.05 #@param {type:\"number\"}\n",
        "resume = 0 #@param {type:\"integer\"}\n",
        "\n",
        "# data_dir = os.path.join(data_dir, 'data', dataset)\n",
        "model_dir = os.path.join(work_dir, 'train', dataset)\n",
        "img_size = int(size)\n",
        "steps = steps_k * 1000\n",
        "sample_every = sample_every_k * 1000\n",
        "save_every = save_every_k * 1000\n",
        "\n",
        "%run src/train.py --data_dir $data_dir --model_dir $model_dir --img_size $img_size --batch $batch --total_iters $steps --sample_every $sample_every --save_every $save_every --lambda_ds $lambda_ds --lambda_cyc $lambda_cyc --lambda_sty $lambda_sty --resume $resume"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYlI1fXe8APH"
      },
      "source": [
        "> This will run training process, according to the options in `src/train.py`. \n",
        "There are two types of models, saved under `train/<dataset>` directory: \n",
        "* generators = named as `<dataset>-<size>-<domaincount>-<kiloiters>.pkl` (e.g. `test-256-7-360.pkl`), \n",
        "* full set (suffixed as `nets`/`optims`) to resume training.  \n",
        "Full models are saved every `save_every_k` thousand steps; test samples and generators - every `sample_every_k` thousand steps. Test samples are saved under `train/<dataset>/test`. Check them to follow the progress! \n",
        "\n",
        "> Training duration is defined by `steps_k` (thousands of steps). Reasonable length for batch=6 (which is maximum for size 256 on standard Colab GPU) is 100-120k, taking 5-7 days. Increase batch count if you get GPU with > 16gb RAM. \n",
        "\n",
        "> Set `resume` to the kilo-iterations of the last full model in the training directory to resume from it. Since the optimizer state is also saved, stopping/resuming does not harm the training process.\n",
        "\n",
        "> **NB: Saved models can quickly occupy disk space, watch out for them!**\n",
        "\n",
        "Don't forget to read [some comments/findings](https://github.com/eps696/stargan2) about training details.\n",
        "\n",
        "Other training options:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAqpEFzukpfs"
      },
      "source": [
        "%run src/train.py --help"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "PRatWRXC8APQ"
      },
      "source": [
        "#@title ### Tweak models\n",
        "\n",
        "#@markdown One can mix few models by stochastic averaging all weights:\n",
        "\n",
        "models_dir = 'models' #@param {type:\"string\"}\n",
        "\n",
        "%run src/swa.py --in_dir $models_dir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Njelbgu8APJ"
      },
      "source": [
        "## Generation\n",
        "\n",
        "Let's produce some imagery from the original `afhq` model (get it [here](https://www.dropbox.com/s/etwm810v25h42sn/100000_nets_ema.ckpt?dl=0) and put onto Google drive somewhere under our working directory).  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "9S73oknl8wLU"
      },
      "source": [
        "#@title ### Generator setup\n",
        "!cd $work_dir\n",
        "\n",
        "#@markdown Run this cell and select model from the dropdown form below:\n",
        "print(work_dir)\n",
        "model_select(work_dir)\n",
        "if model[0]=='/': model = model[1:]\n",
        "model = os.path.join(work_dir, model)\n",
        "print('.. selected model', model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBHD0n0i8APJ",
        "cellView": "form"
      },
      "source": [
        "#@title ### Single images processing\n",
        "\n",
        "#@markdown Put image files in the `_in` directory (under our working one) and list `refs` (numbers of domains), separated by dash. This would produce 3 images (one per trained domain in the model) for every input image. Results are saved in the `_out` directory.  \n",
        "\n",
        "refs = '0-1-2' #@param {type:\"string\"}\n",
        "%cd $work_dir\n",
        "%run src/test.py --source _in --model $model --refs $refs\n",
        "\n",
        "# ipython_display(ImageSequenceClip(img_list(out_dir), fps=25), center=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IE49Zf_W9Ak2",
        "cellView": "form"
      },
      "source": [
        "#@title ### Image animation\n",
        "\n",
        "#@markdown Process single image [*put your own file*], interpolating between referenced domains, with specific total duration.\n",
        "\n",
        "image_in = '_in/test.jpg' #@param {type:\"string\"}\n",
        "refs = '0-1-2' #@param {type:\"string\"}\n",
        "frames = 100 #@param {type:\"integer\"}\n",
        "out_dir = '_out/animation' #@param {type:\"string\"}\n",
        "\n",
        "%cd $work_dir\n",
        "%run src/process.py --source $image_in --model $model --out_dir $out_dir --frames $frames --refs $refs\n",
        "HTML(makevid(os.path.join(out_dir, basename(image_in))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwoOBOcR8APK",
        "cellView": "form"
      },
      "source": [
        "#@title ### Video processing\n",
        "\n",
        "#@markdown Process video file [*put your own file*], interpolating between referenced domains.\n",
        "\n",
        "video_in = '_in/test.mp4' #@param {type:\"string\"}\n",
        "refs = '0-1-2' #@param {type:\"string\"}\n",
        "out_dir = '_out/video' #@param {type:\"string\"}\n",
        "\n",
        "in_tmp = os.path.join('_in', basename(video_in))\n",
        "out_tmp = os.path.join(out_dir, basename(video_in))\n",
        "in_ff = os.path.join(in_tmp, '%06d.jpg')\n",
        "\n",
        "%cd $work_dir\n",
        "os.makedirs(in_tmp, exist_ok=True)\n",
        "os.makedirs(out_tmp, exist_ok=True)\n",
        "\n",
        "!ffmpeg -y -v warning -i $video_in $in_ff\n",
        "%run src/process.py --source $in_tmp --model $model --out_dir $out_dir --refs $refs\n",
        "HTML(makevid(out_tmp))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vufHTzNvxJc9",
        "cellView": "form"
      },
      "source": [
        "#@title ### Recurrent generation\n",
        "\n",
        "#@markdown Generate video sequence, interpolating between referenced domains in a feedback loop, switching domain every `fstep` frames.\n",
        "\n",
        "sizeX = 1280 #@param {type:\"integer\"}\n",
        "sizeY = 720 #@param {type:\"integer\"}\n",
        "refs = '0-1-2' #@param {type:\"string\"}\n",
        "frames = 100 #@param {type:\"integer\"}\n",
        "fstep = 25 #@param {type:\"integer\"}\n",
        "out_dir = '_out/recurs' #@param {type:\"string\"}\n",
        "\n",
        "%cd $work_dir\n",
        "%run src/process.py --model $model --refs $refs --size $sizeX-$sizeY --frames $frames --fstep 25 --out_dir $out_dir --recurs 1\n",
        "HTML(makevid(out_dir))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqeXIYHYxOO9",
        "cellView": "form"
      },
      "source": [
        "#@title ### Recurrent drawing over mask\n",
        "\n",
        "#@markdown Generate similar video sequence, drawing over contour mask (useful for videomapping projections):\n",
        "\n",
        "mask_image = '_in/mapping.jpg' #@param {type:\"string\"}\n",
        "refs = '0-1-2' #@param {type:\"string\"}\n",
        "frames = 100 #@param {type:\"integer\"}\n",
        "fstep = 25 #@param {type:\"integer\"}\n",
        "recurrence = 0.4 #@param {type:\"number\"}\n",
        "sizeX = 1280 #@param {type:\"integer\"}\n",
        "sizeY = 720 #@param {type:\"integer\"}\n",
        "out_dir = '_out/mapping' #@param {type:\"string\"}\n",
        "\n",
        "%cd $work_dir\n",
        "%run src/process.py --source $mask_image --model $model --refs $refs --size $sizeX-$sizeY --frames $frames --fstep 25 --out_dir $out_dir --recurs $recurrence\n",
        "HTML(makevid(os.path.join(out_dir, basename(mask_image))))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}